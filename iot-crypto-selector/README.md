# IoT Cryptographic Algorithm Selection Tool

An explainable decision support system for selecting lightweight cryptographic algorithms in IoT applications.

## ğŸ“Š Project Overview

This project develops a machine learning-based tool that helps IoT developers choose appropriate lightweight cryptographic algorithms based on their device constraints and requirements. The tool provides transparent explanations for its recommendations using SHAP (SHapley Additive exPlanations).

## ğŸ¯ Results Summary

- **Dataset**: 104 high-quality data points from 9 research papers
- **Algorithms**: AES-128, SIMON, SPECK, PRESENT
- **Best Model**: Random Forest
- **Accuracy**: 66.67% (test), 53.71% Â± 20.14% (cross-validation)
- **Key Finding**: Key size is the most important factor (28% importance)

## ğŸ”§ Features

- **Algorithm Recommendation**: Suggests optimal cryptographic algorithm based on device specifications
- **Explainable AI**: SHAP-based explanations for transparency
- **Web Interface**: User-friendly input form and visualization
- **Multi-Platform Support**: Covers 8-bit MCUs, 32-bit MCUs, FPGAs, ASICs

## ğŸ“ Repository Structure

```
iot-crypto-selector/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ final_core4_dataset.csv    # 104 data points
â”‚   â”‚   â””â”€â”€ FINAL_DATASET_SUMMARY.txt   # Dataset statistics
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ dataset_151_processed.csv   # Processed with features
â”‚       â”œâ”€â”€ train_set.csv              # Training data
â”‚       â””â”€â”€ test_set.csv               # Test data
â”œâ”€â”€ models/
â”‚   â””â”€â”€ final_model_151points_*.pkl    # Trained Random Forest model
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ confusion_matrix_*.png         # Model performance
â”‚   â””â”€â”€ shap_importance_*.png          # Feature importance
â”œâ”€â”€ visualizations/                     # Additional plots
â””â”€â”€ *.py                               # Python scripts
```

## ğŸš€ Quick Start

1. **Setup Environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

2. **Run Analysis**
```bash
python dataset_preparation.py    # Prepare data
python complete_analysis.py      # Train model
python generate_explanations.py  # Generate SHAP explanations
```

3. **Analyze Results**
```bash
python results_analysis_script.py  # Understand the dataset
```

## ğŸ“ˆ Key Results

### Algorithm Distribution
- SIMON: 43 samples (41.3%)
- SPECK: 35 samples (33.7%)
- AES-128: 15 samples (14.4%)
- PRESENT: 11 samples (10.6%)

### Performance by Algorithm
| Algorithm | Precision | Recall | F1-Score | Support |
|-----------|-----------|--------|----------|---------|
| AES-128   | 1.00      | 0.33   | 0.50     | 3       |
| PRESENT   | 1.00      | 1.00   | 1.00     | 2       |
| SIMON     | 0.58      | 0.78   | 0.67     | 9       |
| SPECK     | 0.67      | 0.57   | 0.62     | 7       |

### Feature Importance (SHAP)
1. Key_Size_Bits: 28.0%
2. freq_per_kb_ram: 14.9%
3. RAM_KB: 12.9%
4. log_cpu_freq: 11.5%
5. CPU_Freq_MHz: 8.8%

## ğŸ“ Academic Context

This project is part of an undergraduate thesis in Computer Science. While the achieved accuracy (66.67%) is below the initial target (85%), it demonstrates:

- The feasibility of ML-based cryptographic algorithm selection
- The importance of explainable AI in security decisions
- The challenges of working with limited, imbalanced datasets
- The value of honest academic reporting

## âš ï¸ Limitations

1. **Dataset Size**: 104 points (target was 150-200)
2. **Class Imbalance**: SIMON has 3.9x more samples than PRESENT
3. **Accuracy**: 66.67% indicates room for improvement
4. **Scope**: Only 4 algorithms covered

## ğŸ”® Future Work

1. Collect more balanced data (50+ samples per algorithm)
2. Implement advanced balancing techniques (SMOTE)
3. Include energy consumption metrics
4. Expand to more algorithms (ChaCha20, ASCON)
5. Deploy as web service

## ğŸ“š Data Sources

Data extracted from 9 peer-reviewed papers:
- Diehl et al. (2017)
- Sleem & Couturier (2021)
- Nithya & Kumar (2016)
- Bogdanov et al. (2007)
- Beaulieu et al. (2013)
- Dinu et al. (2015)
- [Your original 3 papers]

## ğŸ¤ Contributing

This is an academic project. Contributions in the form of:
- Additional benchmark data
- Improved ML models
- Bug fixes
- Documentation improvements

are welcome via pull requests.

## ğŸ“„ License

This project is released under the MIT License for academic and research purposes.

## ğŸ™ Acknowledgments

- Thesis supervisor for guidance
- Authors of the benchmark papers
- SHAP library developers
- scikit-learn community

---

**Note**: This tool is a proof-of-concept for academic purposes. For production use, additional validation and higher accuracy would be required.